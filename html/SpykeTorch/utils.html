<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.10.0" />
<title>SpykeTorch.utils API documentation</title>
<meta name="description" content="" />
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/sanitize.min.css" integrity="sha256-PK9q560IAAa6WVRRh76LtCaI8pjTJ2z11v0miyNNjrs=" crossorigin>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/typography.min.css" integrity="sha256-7l/o7C8jubJiy74VsKTidCy1yBkRtiUGbVkYBylBqUg=" crossorigin>
<link rel="stylesheet preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/styles/github.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS_CHTML" integrity="sha256-kZafAc6mZvK3W3v1pHOcUix30OHQN6pU/NO2oFkqZVw=" crossorigin></script>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/highlight.min.js" integrity="sha256-Uv3H6lx7dJmRfRvH8TH6kJD1TSK1aFcwgx+mdg3epi8=" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting())</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>SpykeTorch.utils</code></h1>
</header>
<section id="section-intro">
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">import torch
import torch.nn.functional as fn
import numpy as np
import math
from torchvision import transforms
from torchvision import datasets
import os

def to_pair(data):
    r&#34;&#34;&#34;Converts a single or a tuple of data into a pair. If the data is a tuple with more than two elements, it selects
    the first two of them. In case of single data, it duplicates that data into a pair.

    Args:
        data (object or tuple): The input data.

    Returns:
        Tuple: A pair of data.
    &#34;&#34;&#34;
    if isinstance(data, tuple):
        return data[0:2]
    return (data, data)

def generate_inhibition_kernel(inhibition_percents):
    r&#34;&#34;&#34;Generates an inhibition kernel suitable to be used by :func:`~functional.intensity_lateral_inhibition`.

    Args:
        inhibition_percents (sequence): The sequence of inhibition factors (in range [0,1]).

    Returns:
        Tensor: Inhibition kernel.
    &#34;&#34;&#34;
    inhibition_kernel = torch.zeros(2*len(inhibition_percents)+1, 2*len(inhibition_percents)+1).float()
    center = len(inhibition_percents)
    for i in range(2*len(inhibition_percents)+1):
        for j in range(2*len(inhibition_percents)+1):
            dist = int(max(math.fabs(i - center), math.fabs(j - center)))
            if dist != 0:
                inhibition_kernel[i,j] = inhibition_percents[dist - 1]
    return inhibition_kernel

def tensor_to_text(data, address):
    r&#34;&#34;&#34;Saves a tensor into a text file in row-major format. The first line of the file contains comma-separated integers denoting
    the size of each dimension. The second line contains comma-separated values indicating all the tensor&#39;s data.

    Args:
        data (Tensor): The tensor to be saved.
        address (str): The saving address.
    &#34;&#34;&#34;
    f = open(address, &#34;w&#34;)
    data_cpu = data.cpu()
    shape = data.shape
    print(&#34;,&#34;.join(map(str, shape)), file=f)
    data_flat = data_cpu.view(-1).numpy()
    print(&#34;,&#34;.join(data_flat.astype(np.str)), file=f)
    f.close()

def text_to_tensor(address, type=&#39;float&#39;):
    r&#34;&#34;&#34;Loads a tensor from a text file. Format of the text file is as follows: The first line of the file contains comma-separated integers denoting
    the size of each dimension. The second line contains comma-separated values indicating all the tensor&#39;s data.

    Args:
        address (str): Address of the text file.
        type (float or int, optional): The type of the tensor&#39;s data (&#39;float&#39; or &#39;int&#39;). Default: &#39;float&#39;

    Returns:
        Tensor: The loaded tensor.
    &#34;&#34;&#34;
    f = open(address, &#34;r&#34;)
    shape = tuple(map(int, f.readline().split(&#34;,&#34;)))
    data = np.array(f.readline().split(&#34;,&#34;))
    if type == &#39;float&#39;:
        data = data.astype(np.float32)
    elif type == &#39;int&#39;:
        data = data.astype(np.int32)
    else:
        raise ValueError(&#34;type must be &#39;int&#39; or &#39;float&#39;&#34;)
    data = torch.from_numpy(data)
    data = data.reshape(shape)
    f.close()
    return data

class LateralIntencityInhibition:
    r&#34;&#34;&#34;Applies lateral inhibition on intensities. For each location, this inhibition decreases the intensity of the
    surrounding cells that has lower intensities by a specific factor. This factor is relative to the distance of the
    neighbors and are put in the :attr:`inhibition_percents`.

    Args:
        inhibition_percents (sequence): The sequence of inhibition factors (in range [0,1]).
    &#34;&#34;&#34;
    def __init__(self, inhibition_percents):
        self.inhibition_kernel = generate_inhibition_kernel(inhibition_percents)
        self.inhibition_kernel.unsqueeze_(0).unsqueeze_(0)

    # decrease lateral intencities by factors given in the inhibition_kernel
    def intensity_lateral_inhibition(self, intencities):
        intencities.squeeze_(0)
        intencities.unsqueeze_(1)

        inh_win_size = self.inhibition_kernel.size(-1)
        rad = inh_win_size//2
        # repeat each value
        values = intencities.reshape(intencities.size(0),intencities.size(1),-1,1)
        values = values.repeat(1,1,1,inh_win_size)
        values = values.reshape(intencities.size(0),intencities.size(1),-1,intencities.size(-1)*inh_win_size)
        values = values.repeat(1,1,1,inh_win_size)
        values = values.reshape(intencities.size(0),intencities.size(1),-1,intencities.size(-1)*inh_win_size)
        # extend patches
        padded = fn.pad(intencities,(rad,rad,rad,rad))
        # column-wise
        patches = padded.unfold(-1,inh_win_size,1)
        patches = patches.reshape(patches.size(0),patches.size(1),patches.size(2),-1,patches.size(3)*patches.size(4))
        patches.squeeze_(-2)
        # row-wise
        patches = patches.unfold(-2,inh_win_size,1).transpose(-1,-2)
        patches = patches.reshape(patches.size(0),patches.size(1),1,-1,patches.size(-1))
        patches.squeeze_(-3)
        # compare each element by its neighbors
        coef = values - patches
        coef.clamp_(min=0).sign_() # &#34;ones&#34; are neighbors greater than center
        # convolution with full stride to get accumulative inhibiiton factor
        factors = fn.conv2d(coef, self.inhibition_kernel, stride=inh_win_size)
        result = intencities + intencities * factors

        intencities.squeeze_(1)
        intencities.unsqueeze_(0)
        result.squeeze_(1)
        result.unsqueeze_(0)
        return result

    def __call__(self,input):
        return self.intensity_lateral_inhibition(input)

class FilterKernel:
    r&#34;&#34;&#34;Base class for generating image filter kernels such as Gabor, DoG, etc. Each subclass should override :attr:`__call__` function.
    &#34;&#34;&#34;
    def __init__(self, window_size):
        self.window_size = window_size

    def __call__(self):
        pass

class DoGKernel(FilterKernel):
    r&#34;&#34;&#34;Generates DoG filter kernel.

    Args:
        window_size (int): The size of the window (square window).
        sigma1 (float): The sigma for the first Gaussian function.
        sigma2 (float): The sigma for the second Gaussian function.
    &#34;&#34;&#34;
    def __init__(self, window_size, sigma1, sigma2):
        super(DoGKernel, self).__init__(window_size)
        self.sigma1 = sigma1
        self.sigma2 = sigma2

    # returns a 2d tensor corresponding to the requested DoG filter
    def __call__(self):
        w = self.window_size//2
        x, y = np.mgrid[-w:w+1:1, -w:w+1:1]
        a = 1.0 / (2 * math.pi)
        prod = x*x + y*y
        f1 = (1/(self.sigma1*self.sigma1)) * np.exp(-0.5 * (1/(self.sigma1*self.sigma1)) * (prod))
        f2 = (1/(self.sigma2*self.sigma2)) * np.exp(-0.5 * (1/(self.sigma2*self.sigma2)) * (prod))
        dog = a * (f1-f2)
        dog_mean = np.mean(dog)
        dog = dog - dog_mean
        dog_max = np.max(dog)
        dog = dog / dog_max
        dog_tensor = torch.from_numpy(dog)
        return dog_tensor.float()

class GaborKernel(FilterKernel):
    r&#34;&#34;&#34;Generates Gabor filter kernel.

    Args:
        window_size (int): The size of the window (square window).
        orientation (float): The orientation of the Gabor filter (in degrees).
        div (float, optional): The divisor of the lambda equation. Default: 4.0
    &#34;&#34;&#34;
    def __init__(self, window_size, orientation, div=4.0):
        super(GaborKernel, self).__init__(window_size)
        self.orientation = orientation
        self.div = div

    # returns a 2d tensor corresponding to the requested Gabor filter
    def __call__(self):
        w = self.window_size//2
        x, y = np.mgrid[-w:w+1:1, -w:w+1:1]
        lamda = self.window_size * 2 / self.div
        sigma = lamda * 0.8
        sigmaSq = sigma * sigma
        g = 0.3;
        theta = (self.orientation * np.pi) / 180;
        Y = y*np.cos(theta) - x*np.sin(theta)
        X = y*np.sin(theta) + x*np.cos(theta)
        gabor = np.exp(-(X * X + g * g * Y * Y) / (2 * sigmaSq)) * np.cos(2 * np.pi * X / lamda);
        gabor_mean = np.mean(gabor)
        gabor = gabor - gabor_mean
        gabor_max = np.max(gabor)
        gabor = gabor / gabor_max
        gabor_tensor = torch.from_numpy(gabor)
        return gabor_tensor.float()

class Filter:
    r&#34;&#34;&#34;Applies a filter transform. Each filter contains a sequence of :attr:`FilterKernel` objects.
    The result of each filter kernel will be passed through a given threshold (if not :attr:`None`).

    Args:
        filter_kernels (sequence of FilterKernels): The sequence of filter kernels.
        padding (int, optional): The size of the padding for the convolution of filter kernels. Default: 0
        thresholds (sequence of floats, optional): The threshold for each filter kernel. Default: None
        use_abs (boolean, optional): To compute the absolute value of the outputs or not. Default: False

    .. note::

        The size of the compund filter kernel tensor (stack of individual filter kernels) will be equal to the 
        greatest window size among kernels. All other smaller kernels will be zero-padded with an appropriate 
        amount.
    &#34;&#34;&#34;
    # filter_kernels must be a list of filter kernels
    # thresholds must be a list of thresholds for each kernel
    def __init__(self, filter_kernels, padding=0, thresholds=None, use_abs=False):
        tensor_list = []
        self.max_window_size = 0
        for kernel in filter_kernels:
            if isinstance(kernel, torch.Tensor):
                tensor_list.append(kernel)
                self.max_window_size = max(self.max_window_size, kernel.size(-1))
            else:
                tensor_list.append(kernel().unsqueeze(0))
                self.max_window_size = max(self.max_window_size, kernel.window_size)
        for i in range(len(tensor_list)):
            p = (self.max_window_size - filter_kernels[i].window_size)//2
            tensor_list[i] = fn.pad(tensor_list[i], (p,p,p,p))

        self.kernels = torch.stack(tensor_list)
        self.number_of_kernels = len(filter_kernels)
        self.padding = padding
        if isinstance(thresholds, list):
            self.thresholds = thresholds.clone().detach()
            self.thresholds.unsqueeze_(0).unsqueeze_(2).unsqueeze_(3)
        else:
            self.thresholds = thresholds
        self.use_abs = use_abs

    # returns a 4d tensor containing the flitered versions of the input image
    # input is a 4d tensor. dim: (minibatch=1, filter_kernels, height, width)
    def __call__(self, input):
        output = fn.conv2d(input, self.kernels, padding = self.padding).float()
        if not(self.thresholds is None):
            output = torch.where(output &lt; self.thresholds, torch.tensor(0.0, device=output.device), output)
        if self.use_abs:
            torch.abs_(output)
        return output

class Intensity2Latency:
    r&#34;&#34;&#34;Applies intensity to latency transform. Spike waves are generated in the form of
    spike bins with almost equal number of spikes.

    Args:
        number_of_spike_bins (int): Number of spike bins (time steps).
        to_spike (boolean, optional): To generate spike-wave tensor or not. Default: False

    .. note::

        If :attr:`to_spike` is :attr:`False`, then the result is intesities that are ordered and packed into bins.
    &#34;&#34;&#34;
    def __init__(self, number_of_spike_bins, to_spike=False):
        self.time_steps = number_of_spike_bins
        self.to_spike = to_spike
    
    # intencities is a tensor of input intencities (1, input_channels, height, width)
    # returns a tensor of tensors containing spikes in each timestep (considers minibatch for timesteps)
    # spikes are accumulative, i.e. spikes in timestep i are also presented in i+1, i+2, ...
    def intensity_to_latency(self, intencities):
        #bins = []
        bins_intencities = []
        nonzero_cnt = torch.nonzero(intencities).size()[0]

        #check for empty bins
        bin_size = nonzero_cnt//self.time_steps

        #sort
        intencities_flattened = torch.reshape(intencities, (-1,))
        intencities_flattened_sorted = torch.sort(intencities_flattened, descending=True)

        #bin packing
        sorted_bins_value, sorted_bins_idx = torch.split(intencities_flattened_sorted[0], bin_size), torch.split(intencities_flattened_sorted[1], bin_size)

        #add to the list of timesteps
        spike_map = torch.zeros_like(intencities_flattened_sorted[0])
    
        for i in range(self.time_steps):
            spike_map.scatter_(0, sorted_bins_idx[i], sorted_bins_value[i])
            spike_map_copy = spike_map.clone().detach()
            spike_map_copy = spike_map_copy.reshape(tuple(intencities.shape))
            bins_intencities.append(spike_map_copy.squeeze(0).float())
            #bins.append(spike_map_copy.sign().squeeze_(0).float())
    
        return torch.stack(bins_intencities)#, torch.stack(bins)
        #return torch.stack(bins)

    def __call__(self, image):
        if self.to_spike:
            return self.intensity_to_latency(image).sign()
        return self.intensity_to_latency(image)

#class ImageFolderCache(datasets.ImageFolder):
#       def __init__(self, root, transform=None, target_transform=None,
#                 loader=datasets.folder.default_loader, cache_address=None):
#               super(ImageFolderCache, self).__init__(root, transform=transform, target_transform=target_transform, loader=loader)
#               self.imgs = self.samples
#               self.cache_address = cache_address
#               self.cache = [None] * len(self)

#       def __getitem__(self, index):
#               path, target = self.samples[index]
#               if self.cache[index] is None:
#                       sample = self.loader(path)
#                       if self.transform is not None:
#                               sample = self.transform(sample)
#                       if self.target_transform is not None:
#                               target = self.target_transform(target)

#                       #cache it
#                       if self.cache_address is None:
#                               self.cache[index] = sample
#                       else:
#                               save_path = os.path.join(self.cache_address, str(index)+&#39;.c&#39;)
#                               torch.save(sample, save_path)
#                               self.cache[index] = save_path
#               else:
#                       if self.cache_address is None:
#                               sample = self.cache[index]
#                       else:
#                               sample = torch.load(self.cache[index])
#               return sample, target

#       def reset_cache(self):
#               self.cache = [None] * len(self)

class CacheDataset(torch.utils.data.Dataset):
    r&#34;&#34;&#34;A wrapper dataset to cache pre-processed data. It can cache data on RAM or a secondary memory.

    .. note::

        Since converting image into spike-wave can be time consuming, we recommend to wrap your dataset into a :attr:`CacheDataset`
        object.

    Args:
        dataset (torch.utils.data.Dataset): The reference dataset object.
        cache_address (str, optional): The location of cache in the secondary memory. Use :attr:`None` to cache on RAM. Default: None
    &#34;&#34;&#34;
    def __init__(self, dataset, cache_address=None):
        self.dataset = dataset
        self.cache_address = cache_address
        self.cache = [None] * len(self.dataset)

    def __getitem__(self, index):
        if self.cache[index] is None:
            #cache it
            sample, target = self.dataset[index]
            if self.cache_address is None:
                self.cache[index] = sample, target
            else:
                save_path = os.path.join(self.cache_address, str(index))
                torch.save(sample, save_path + &#34;.cd&#34;)
                torch.save(target, save_path + &#34;.cl&#34;)
                self.cache[index] = save_path
        else:
            if self.cache_address is None:
                sample, target = self.cache[index]
            else:
                sample = torch.load(self.cache[index] + &#34;.cd&#34;)
                target = torch.load(self.cache[index] + &#34;.cl&#34;)
        return sample, target

    def reset_cache(self):
        r&#34;&#34;&#34;Clears the cached data. It is useful when you want to change a pre-processing parameter during
        the training process.
        &#34;&#34;&#34;
        if self.cache_address is not None:
            for add in self.cache:
                os.remove(add + &#34;.cd&#34;)
                os.remove(add + &#34;.cl&#34;)
        self.cache = [None] * len(self)

    def __len__(self):
        return len(self.dataset)</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-functions">Functions</h2>
<dl>
<dt id="SpykeTorch.utils.to_pair"><code class="name flex">
<span>def <span class="ident">to_pair</span></span>(<span>data)</span>
</code></dt>
<dd>
<div class="desc"><p>Converts a single or a tuple of data into a pair. If the data is a tuple with more than two elements, it selects
the first two of them. In case of single data, it duplicates that data into a pair.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>data</code></strong> :&ensp;<code>object</code> or <code>tuple</code></dt>
<dd>The input data.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>Tuple</code></dt>
<dd>A pair of data.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def to_pair(data):
    r&#34;&#34;&#34;Converts a single or a tuple of data into a pair. If the data is a tuple with more than two elements, it selects
    the first two of them. In case of single data, it duplicates that data into a pair.

    Args:
        data (object or tuple): The input data.

    Returns:
        Tuple: A pair of data.
    &#34;&#34;&#34;
    if isinstance(data, tuple):
        return data[0:2]
    return (data, data)</code></pre>
</details>
</dd>
<dt id="SpykeTorch.utils.generate_inhibition_kernel"><code class="name flex">
<span>def <span class="ident">generate_inhibition_kernel</span></span>(<span>inhibition_percents)</span>
</code></dt>
<dd>
<div class="desc"><p>Generates an inhibition kernel suitable to be used by :func:<code>~functional.intensity_lateral_inhibition</code>.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>inhibition_percents</code></strong> :&ensp;<code>sequence</code></dt>
<dd>The sequence of inhibition factors (in range [0,1]).</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>Tensor</code></dt>
<dd>Inhibition kernel.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def generate_inhibition_kernel(inhibition_percents):
    r&#34;&#34;&#34;Generates an inhibition kernel suitable to be used by :func:`~functional.intensity_lateral_inhibition`.

    Args:
        inhibition_percents (sequence): The sequence of inhibition factors (in range [0,1]).

    Returns:
        Tensor: Inhibition kernel.
    &#34;&#34;&#34;
    inhibition_kernel = torch.zeros(2*len(inhibition_percents)+1, 2*len(inhibition_percents)+1).float()
    center = len(inhibition_percents)
    for i in range(2*len(inhibition_percents)+1):
        for j in range(2*len(inhibition_percents)+1):
            dist = int(max(math.fabs(i - center), math.fabs(j - center)))
            if dist != 0:
                inhibition_kernel[i,j] = inhibition_percents[dist - 1]
    return inhibition_kernel</code></pre>
</details>
</dd>
<dt id="SpykeTorch.utils.tensor_to_text"><code class="name flex">
<span>def <span class="ident">tensor_to_text</span></span>(<span>data, address)</span>
</code></dt>
<dd>
<div class="desc"><p>Saves a tensor into a text file in row-major format. The first line of the file contains comma-separated integers denoting
the size of each dimension. The second line contains comma-separated values indicating all the tensor's data.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>data</code></strong> :&ensp;<code>Tensor</code></dt>
<dd>The tensor to be saved.</dd>
<dt><strong><code>address</code></strong> :&ensp;<code>str</code></dt>
<dd>The saving address.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def tensor_to_text(data, address):
    r&#34;&#34;&#34;Saves a tensor into a text file in row-major format. The first line of the file contains comma-separated integers denoting
    the size of each dimension. The second line contains comma-separated values indicating all the tensor&#39;s data.

    Args:
        data (Tensor): The tensor to be saved.
        address (str): The saving address.
    &#34;&#34;&#34;
    f = open(address, &#34;w&#34;)
    data_cpu = data.cpu()
    shape = data.shape
    print(&#34;,&#34;.join(map(str, shape)), file=f)
    data_flat = data_cpu.view(-1).numpy()
    print(&#34;,&#34;.join(data_flat.astype(np.str)), file=f)
    f.close()</code></pre>
</details>
</dd>
<dt id="SpykeTorch.utils.text_to_tensor"><code class="name flex">
<span>def <span class="ident">text_to_tensor</span></span>(<span>address, type='float')</span>
</code></dt>
<dd>
<div class="desc"><p>Loads a tensor from a text file. Format of the text file is as follows: The first line of the file contains comma-separated integers denoting
the size of each dimension. The second line contains comma-separated values indicating all the tensor's data.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>address</code></strong> :&ensp;<code>str</code></dt>
<dd>Address of the text file.</dd>
<dt><strong><code>type</code></strong> :&ensp;<code>float</code> or <code>int</code>, optional</dt>
<dd>The type of the tensor's data ('float' or 'int'). Default: 'float'</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>Tensor</code></dt>
<dd>The loaded tensor.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def text_to_tensor(address, type=&#39;float&#39;):
    r&#34;&#34;&#34;Loads a tensor from a text file. Format of the text file is as follows: The first line of the file contains comma-separated integers denoting
    the size of each dimension. The second line contains comma-separated values indicating all the tensor&#39;s data.

    Args:
        address (str): Address of the text file.
        type (float or int, optional): The type of the tensor&#39;s data (&#39;float&#39; or &#39;int&#39;). Default: &#39;float&#39;

    Returns:
        Tensor: The loaded tensor.
    &#34;&#34;&#34;
    f = open(address, &#34;r&#34;)
    shape = tuple(map(int, f.readline().split(&#34;,&#34;)))
    data = np.array(f.readline().split(&#34;,&#34;))
    if type == &#39;float&#39;:
        data = data.astype(np.float32)
    elif type == &#39;int&#39;:
        data = data.astype(np.int32)
    else:
        raise ValueError(&#34;type must be &#39;int&#39; or &#39;float&#39;&#34;)
    data = torch.from_numpy(data)
    data = data.reshape(shape)
    f.close()
    return data</code></pre>
</details>
</dd>
</dl>
</section>
<section>
<h2 class="section-title" id="header-classes">Classes</h2>
<dl>
<dt id="SpykeTorch.utils.LateralIntencityInhibition"><code class="flex name class">
<span>class <span class="ident">LateralIntencityInhibition</span></span>
<span>(</span><span>inhibition_percents)</span>
</code></dt>
<dd>
<div class="desc"><p>Applies lateral inhibition on intensities. For each location, this inhibition decreases the intensity of the
surrounding cells that has lower intensities by a specific factor. This factor is relative to the distance of the
neighbors and are put in the :attr:<code>inhibition_percents</code>.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>inhibition_percents</code></strong> :&ensp;<code>sequence</code></dt>
<dd>The sequence of inhibition factors (in range [0,1]).</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class LateralIntencityInhibition:
    r&#34;&#34;&#34;Applies lateral inhibition on intensities. For each location, this inhibition decreases the intensity of the
    surrounding cells that has lower intensities by a specific factor. This factor is relative to the distance of the
    neighbors and are put in the :attr:`inhibition_percents`.

    Args:
        inhibition_percents (sequence): The sequence of inhibition factors (in range [0,1]).
    &#34;&#34;&#34;
    def __init__(self, inhibition_percents):
        self.inhibition_kernel = generate_inhibition_kernel(inhibition_percents)
        self.inhibition_kernel.unsqueeze_(0).unsqueeze_(0)

    # decrease lateral intencities by factors given in the inhibition_kernel
    def intensity_lateral_inhibition(self, intencities):
        intencities.squeeze_(0)
        intencities.unsqueeze_(1)

        inh_win_size = self.inhibition_kernel.size(-1)
        rad = inh_win_size//2
        # repeat each value
        values = intencities.reshape(intencities.size(0),intencities.size(1),-1,1)
        values = values.repeat(1,1,1,inh_win_size)
        values = values.reshape(intencities.size(0),intencities.size(1),-1,intencities.size(-1)*inh_win_size)
        values = values.repeat(1,1,1,inh_win_size)
        values = values.reshape(intencities.size(0),intencities.size(1),-1,intencities.size(-1)*inh_win_size)
        # extend patches
        padded = fn.pad(intencities,(rad,rad,rad,rad))
        # column-wise
        patches = padded.unfold(-1,inh_win_size,1)
        patches = patches.reshape(patches.size(0),patches.size(1),patches.size(2),-1,patches.size(3)*patches.size(4))
        patches.squeeze_(-2)
        # row-wise
        patches = patches.unfold(-2,inh_win_size,1).transpose(-1,-2)
        patches = patches.reshape(patches.size(0),patches.size(1),1,-1,patches.size(-1))
        patches.squeeze_(-3)
        # compare each element by its neighbors
        coef = values - patches
        coef.clamp_(min=0).sign_() # &#34;ones&#34; are neighbors greater than center
        # convolution with full stride to get accumulative inhibiiton factor
        factors = fn.conv2d(coef, self.inhibition_kernel, stride=inh_win_size)
        result = intencities + intencities * factors

        intencities.squeeze_(1)
        intencities.unsqueeze_(0)
        result.squeeze_(1)
        result.unsqueeze_(0)
        return result

    def __call__(self,input):
        return self.intensity_lateral_inhibition(input)</code></pre>
</details>
<h3>Methods</h3>
<dl>
<dt id="SpykeTorch.utils.LateralIntencityInhibition.intensity_lateral_inhibition"><code class="name flex">
<span>def <span class="ident">intensity_lateral_inhibition</span></span>(<span>self, intencities)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def intensity_lateral_inhibition(self, intencities):
    intencities.squeeze_(0)
    intencities.unsqueeze_(1)

    inh_win_size = self.inhibition_kernel.size(-1)
    rad = inh_win_size//2
    # repeat each value
    values = intencities.reshape(intencities.size(0),intencities.size(1),-1,1)
    values = values.repeat(1,1,1,inh_win_size)
    values = values.reshape(intencities.size(0),intencities.size(1),-1,intencities.size(-1)*inh_win_size)
    values = values.repeat(1,1,1,inh_win_size)
    values = values.reshape(intencities.size(0),intencities.size(1),-1,intencities.size(-1)*inh_win_size)
    # extend patches
    padded = fn.pad(intencities,(rad,rad,rad,rad))
    # column-wise
    patches = padded.unfold(-1,inh_win_size,1)
    patches = patches.reshape(patches.size(0),patches.size(1),patches.size(2),-1,patches.size(3)*patches.size(4))
    patches.squeeze_(-2)
    # row-wise
    patches = patches.unfold(-2,inh_win_size,1).transpose(-1,-2)
    patches = patches.reshape(patches.size(0),patches.size(1),1,-1,patches.size(-1))
    patches.squeeze_(-3)
    # compare each element by its neighbors
    coef = values - patches
    coef.clamp_(min=0).sign_() # &#34;ones&#34; are neighbors greater than center
    # convolution with full stride to get accumulative inhibiiton factor
    factors = fn.conv2d(coef, self.inhibition_kernel, stride=inh_win_size)
    result = intencities + intencities * factors

    intencities.squeeze_(1)
    intencities.unsqueeze_(0)
    result.squeeze_(1)
    result.unsqueeze_(0)
    return result</code></pre>
</details>
</dd>
</dl>
</dd>
<dt id="SpykeTorch.utils.FilterKernel"><code class="flex name class">
<span>class <span class="ident">FilterKernel</span></span>
<span>(</span><span>window_size)</span>
</code></dt>
<dd>
<div class="desc"><p>Base class for generating image filter kernels such as Gabor, DoG, etc. Each subclass should override :attr:<code>__call__</code> function.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class FilterKernel:
    r&#34;&#34;&#34;Base class for generating image filter kernels such as Gabor, DoG, etc. Each subclass should override :attr:`__call__` function.
    &#34;&#34;&#34;
    def __init__(self, window_size):
        self.window_size = window_size

    def __call__(self):
        pass</code></pre>
</details>
<h3>Subclasses</h3>
<ul class="hlist">
<li><a title="SpykeTorch.utils.DoGKernel" href="#SpykeTorch.utils.DoGKernel">DoGKernel</a></li>
<li><a title="SpykeTorch.utils.GaborKernel" href="#SpykeTorch.utils.GaborKernel">GaborKernel</a></li>
</ul>
</dd>
<dt id="SpykeTorch.utils.DoGKernel"><code class="flex name class">
<span>class <span class="ident">DoGKernel</span></span>
<span>(</span><span>window_size, sigma1, sigma2)</span>
</code></dt>
<dd>
<div class="desc"><p>Generates DoG filter kernel.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>window_size</code></strong> :&ensp;<code>int</code></dt>
<dd>The size of the window (square window).</dd>
<dt><strong><code>sigma1</code></strong> :&ensp;<code>float</code></dt>
<dd>The sigma for the first Gaussian function.</dd>
<dt><strong><code>sigma2</code></strong> :&ensp;<code>float</code></dt>
<dd>The sigma for the second Gaussian function.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class DoGKernel(FilterKernel):
    r&#34;&#34;&#34;Generates DoG filter kernel.

    Args:
        window_size (int): The size of the window (square window).
        sigma1 (float): The sigma for the first Gaussian function.
        sigma2 (float): The sigma for the second Gaussian function.
    &#34;&#34;&#34;
    def __init__(self, window_size, sigma1, sigma2):
        super(DoGKernel, self).__init__(window_size)
        self.sigma1 = sigma1
        self.sigma2 = sigma2

    # returns a 2d tensor corresponding to the requested DoG filter
    def __call__(self):
        w = self.window_size//2
        x, y = np.mgrid[-w:w+1:1, -w:w+1:1]
        a = 1.0 / (2 * math.pi)
        prod = x*x + y*y
        f1 = (1/(self.sigma1*self.sigma1)) * np.exp(-0.5 * (1/(self.sigma1*self.sigma1)) * (prod))
        f2 = (1/(self.sigma2*self.sigma2)) * np.exp(-0.5 * (1/(self.sigma2*self.sigma2)) * (prod))
        dog = a * (f1-f2)
        dog_mean = np.mean(dog)
        dog = dog - dog_mean
        dog_max = np.max(dog)
        dog = dog / dog_max
        dog_tensor = torch.from_numpy(dog)
        return dog_tensor.float()</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li><a title="SpykeTorch.utils.FilterKernel" href="#SpykeTorch.utils.FilterKernel">FilterKernel</a></li>
</ul>
</dd>
<dt id="SpykeTorch.utils.GaborKernel"><code class="flex name class">
<span>class <span class="ident">GaborKernel</span></span>
<span>(</span><span>window_size, orientation, div=4.0)</span>
</code></dt>
<dd>
<div class="desc"><p>Generates Gabor filter kernel.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>window_size</code></strong> :&ensp;<code>int</code></dt>
<dd>The size of the window (square window).</dd>
<dt><strong><code>orientation</code></strong> :&ensp;<code>float</code></dt>
<dd>The orientation of the Gabor filter (in degrees).</dd>
<dt><strong><code>div</code></strong> :&ensp;<code>float</code>, optional</dt>
<dd>The divisor of the lambda equation. Default: 4.0</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class GaborKernel(FilterKernel):
    r&#34;&#34;&#34;Generates Gabor filter kernel.

    Args:
        window_size (int): The size of the window (square window).
        orientation (float): The orientation of the Gabor filter (in degrees).
        div (float, optional): The divisor of the lambda equation. Default: 4.0
    &#34;&#34;&#34;
    def __init__(self, window_size, orientation, div=4.0):
        super(GaborKernel, self).__init__(window_size)
        self.orientation = orientation
        self.div = div

    # returns a 2d tensor corresponding to the requested Gabor filter
    def __call__(self):
        w = self.window_size//2
        x, y = np.mgrid[-w:w+1:1, -w:w+1:1]
        lamda = self.window_size * 2 / self.div
        sigma = lamda * 0.8
        sigmaSq = sigma * sigma
        g = 0.3;
        theta = (self.orientation * np.pi) / 180;
        Y = y*np.cos(theta) - x*np.sin(theta)
        X = y*np.sin(theta) + x*np.cos(theta)
        gabor = np.exp(-(X * X + g * g * Y * Y) / (2 * sigmaSq)) * np.cos(2 * np.pi * X / lamda);
        gabor_mean = np.mean(gabor)
        gabor = gabor - gabor_mean
        gabor_max = np.max(gabor)
        gabor = gabor / gabor_max
        gabor_tensor = torch.from_numpy(gabor)
        return gabor_tensor.float()</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li><a title="SpykeTorch.utils.FilterKernel" href="#SpykeTorch.utils.FilterKernel">FilterKernel</a></li>
</ul>
</dd>
<dt id="SpykeTorch.utils.Filter"><code class="flex name class">
<span>class <span class="ident">Filter</span></span>
<span>(</span><span>filter_kernels, padding=0, thresholds=None, use_abs=False)</span>
</code></dt>
<dd>
<div class="desc"><p>Applies a filter transform. Each filter contains a sequence of :attr:<code><a title="SpykeTorch.utils.FilterKernel" href="#SpykeTorch.utils.FilterKernel">FilterKernel</a></code> objects.
The result of each filter kernel will be passed through a given threshold (if not :attr:<code>None</code>).</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>filter_kernels</code></strong> :&ensp;<code>sequence</code> of <code>FilterKernels</code></dt>
<dd>The sequence of filter kernels.</dd>
<dt><strong><code>padding</code></strong> :&ensp;<code>int</code>, optional</dt>
<dd>The size of the padding for the convolution of filter kernels. Default: 0</dd>
<dt><strong><code>thresholds</code></strong> :&ensp;<code>sequence</code> of <code>floats</code>, optional</dt>
<dd>The threshold for each filter kernel. Default: None</dd>
<dt><strong><code>use_abs</code></strong> :&ensp;<code>boolean</code>, optional</dt>
<dd>To compute the absolute value of the outputs or not. Default: False</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>The size of the compund filter kernel tensor (stack of individual filter kernels) will be equal to the
greatest window size among kernels. All other smaller kernels will be zero-padded with an appropriate
amount.</p>
</div></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class Filter:
    r&#34;&#34;&#34;Applies a filter transform. Each filter contains a sequence of :attr:`FilterKernel` objects.
    The result of each filter kernel will be passed through a given threshold (if not :attr:`None`).

    Args:
        filter_kernels (sequence of FilterKernels): The sequence of filter kernels.
        padding (int, optional): The size of the padding for the convolution of filter kernels. Default: 0
        thresholds (sequence of floats, optional): The threshold for each filter kernel. Default: None
        use_abs (boolean, optional): To compute the absolute value of the outputs or not. Default: False

    .. note::

        The size of the compund filter kernel tensor (stack of individual filter kernels) will be equal to the 
        greatest window size among kernels. All other smaller kernels will be zero-padded with an appropriate 
        amount.
    &#34;&#34;&#34;
    # filter_kernels must be a list of filter kernels
    # thresholds must be a list of thresholds for each kernel
    def __init__(self, filter_kernels, padding=0, thresholds=None, use_abs=False):
        tensor_list = []
        self.max_window_size = 0
        for kernel in filter_kernels:
            if isinstance(kernel, torch.Tensor):
                tensor_list.append(kernel)
                self.max_window_size = max(self.max_window_size, kernel.size(-1))
            else:
                tensor_list.append(kernel().unsqueeze(0))
                self.max_window_size = max(self.max_window_size, kernel.window_size)
        for i in range(len(tensor_list)):
            p = (self.max_window_size - filter_kernels[i].window_size)//2
            tensor_list[i] = fn.pad(tensor_list[i], (p,p,p,p))

        self.kernels = torch.stack(tensor_list)
        self.number_of_kernels = len(filter_kernels)
        self.padding = padding
        if isinstance(thresholds, list):
            self.thresholds = thresholds.clone().detach()
            self.thresholds.unsqueeze_(0).unsqueeze_(2).unsqueeze_(3)
        else:
            self.thresholds = thresholds
        self.use_abs = use_abs

    # returns a 4d tensor containing the flitered versions of the input image
    # input is a 4d tensor. dim: (minibatch=1, filter_kernels, height, width)
    def __call__(self, input):
        output = fn.conv2d(input, self.kernels, padding = self.padding).float()
        if not(self.thresholds is None):
            output = torch.where(output &lt; self.thresholds, torch.tensor(0.0, device=output.device), output)
        if self.use_abs:
            torch.abs_(output)
        return output</code></pre>
</details>
</dd>
<dt id="SpykeTorch.utils.Intensity2Latency"><code class="flex name class">
<span>class <span class="ident">Intensity2Latency</span></span>
<span>(</span><span>number_of_spike_bins, to_spike=False)</span>
</code></dt>
<dd>
<div class="desc"><p>Applies intensity to latency transform. Spike waves are generated in the form of
spike bins with almost equal number of spikes.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>number_of_spike_bins</code></strong> :&ensp;<code>int</code></dt>
<dd>Number of spike bins (time steps).</dd>
<dt><strong><code>to_spike</code></strong> :&ensp;<code>boolean</code>, optional</dt>
<dd>To generate spike-wave tensor or not. Default: False</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>If :attr:<code>to_spike</code> is :attr:<code>False</code>, then the result is intesities that are ordered and packed into bins.</p>
</div></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class Intensity2Latency:
    r&#34;&#34;&#34;Applies intensity to latency transform. Spike waves are generated in the form of
    spike bins with almost equal number of spikes.

    Args:
        number_of_spike_bins (int): Number of spike bins (time steps).
        to_spike (boolean, optional): To generate spike-wave tensor or not. Default: False

    .. note::

        If :attr:`to_spike` is :attr:`False`, then the result is intesities that are ordered and packed into bins.
    &#34;&#34;&#34;
    def __init__(self, number_of_spike_bins, to_spike=False):
        self.time_steps = number_of_spike_bins
        self.to_spike = to_spike
    
    # intencities is a tensor of input intencities (1, input_channels, height, width)
    # returns a tensor of tensors containing spikes in each timestep (considers minibatch for timesteps)
    # spikes are accumulative, i.e. spikes in timestep i are also presented in i+1, i+2, ...
    def intensity_to_latency(self, intencities):
        #bins = []
        bins_intencities = []
        nonzero_cnt = torch.nonzero(intencities).size()[0]

        #check for empty bins
        bin_size = nonzero_cnt//self.time_steps

        #sort
        intencities_flattened = torch.reshape(intencities, (-1,))
        intencities_flattened_sorted = torch.sort(intencities_flattened, descending=True)

        #bin packing
        sorted_bins_value, sorted_bins_idx = torch.split(intencities_flattened_sorted[0], bin_size), torch.split(intencities_flattened_sorted[1], bin_size)

        #add to the list of timesteps
        spike_map = torch.zeros_like(intencities_flattened_sorted[0])
    
        for i in range(self.time_steps):
            spike_map.scatter_(0, sorted_bins_idx[i], sorted_bins_value[i])
            spike_map_copy = spike_map.clone().detach()
            spike_map_copy = spike_map_copy.reshape(tuple(intencities.shape))
            bins_intencities.append(spike_map_copy.squeeze(0).float())
            #bins.append(spike_map_copy.sign().squeeze_(0).float())
    
        return torch.stack(bins_intencities)#, torch.stack(bins)
        #return torch.stack(bins)

    def __call__(self, image):
        if self.to_spike:
            return self.intensity_to_latency(image).sign()
        return self.intensity_to_latency(image)</code></pre>
</details>
<h3>Methods</h3>
<dl>
<dt id="SpykeTorch.utils.Intensity2Latency.intensity_to_latency"><code class="name flex">
<span>def <span class="ident">intensity_to_latency</span></span>(<span>self, intencities)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def intensity_to_latency(self, intencities):
    #bins = []
    bins_intencities = []
    nonzero_cnt = torch.nonzero(intencities).size()[0]

    #check for empty bins
    bin_size = nonzero_cnt//self.time_steps

    #sort
    intencities_flattened = torch.reshape(intencities, (-1,))
    intencities_flattened_sorted = torch.sort(intencities_flattened, descending=True)

    #bin packing
    sorted_bins_value, sorted_bins_idx = torch.split(intencities_flattened_sorted[0], bin_size), torch.split(intencities_flattened_sorted[1], bin_size)

    #add to the list of timesteps
    spike_map = torch.zeros_like(intencities_flattened_sorted[0])

    for i in range(self.time_steps):
        spike_map.scatter_(0, sorted_bins_idx[i], sorted_bins_value[i])
        spike_map_copy = spike_map.clone().detach()
        spike_map_copy = spike_map_copy.reshape(tuple(intencities.shape))
        bins_intencities.append(spike_map_copy.squeeze(0).float())
        #bins.append(spike_map_copy.sign().squeeze_(0).float())

    return torch.stack(bins_intencities)#, torch.stack(bins)
    #return torch.stack(bins)</code></pre>
</details>
</dd>
</dl>
</dd>
<dt id="SpykeTorch.utils.CacheDataset"><code class="flex name class">
<span>class <span class="ident">CacheDataset</span></span>
<span>(</span><span>dataset, cache_address=None)</span>
</code></dt>
<dd>
<div class="desc"><p>A wrapper dataset to cache pre-processed data. It can cache data on RAM or a secondary memory.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Since converting image into spike-wave can be time consuming, we recommend to wrap your dataset into a :attr:<code><a title="SpykeTorch.utils.CacheDataset" href="#SpykeTorch.utils.CacheDataset">CacheDataset</a></code>
object.</p>
</div>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>dataset</code></strong> :&ensp;<code>torch.utils.data.Dataset</code></dt>
<dd>The reference dataset object.</dd>
<dt><strong><code>cache_address</code></strong> :&ensp;<code>str</code>, optional</dt>
<dd>The location of cache in the secondary memory. Use :attr:<code>None</code> to cache on RAM. Default: None</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class CacheDataset(torch.utils.data.Dataset):
    r&#34;&#34;&#34;A wrapper dataset to cache pre-processed data. It can cache data on RAM or a secondary memory.

    .. note::

        Since converting image into spike-wave can be time consuming, we recommend to wrap your dataset into a :attr:`CacheDataset`
        object.

    Args:
        dataset (torch.utils.data.Dataset): The reference dataset object.
        cache_address (str, optional): The location of cache in the secondary memory. Use :attr:`None` to cache on RAM. Default: None
    &#34;&#34;&#34;
    def __init__(self, dataset, cache_address=None):
        self.dataset = dataset
        self.cache_address = cache_address
        self.cache = [None] * len(self.dataset)

    def __getitem__(self, index):
        if self.cache[index] is None:
            #cache it
            sample, target = self.dataset[index]
            if self.cache_address is None:
                self.cache[index] = sample, target
            else:
                save_path = os.path.join(self.cache_address, str(index))
                torch.save(sample, save_path + &#34;.cd&#34;)
                torch.save(target, save_path + &#34;.cl&#34;)
                self.cache[index] = save_path
        else:
            if self.cache_address is None:
                sample, target = self.cache[index]
            else:
                sample = torch.load(self.cache[index] + &#34;.cd&#34;)
                target = torch.load(self.cache[index] + &#34;.cl&#34;)
        return sample, target

    def reset_cache(self):
        r&#34;&#34;&#34;Clears the cached data. It is useful when you want to change a pre-processing parameter during
        the training process.
        &#34;&#34;&#34;
        if self.cache_address is not None:
            for add in self.cache:
                os.remove(add + &#34;.cd&#34;)
                os.remove(add + &#34;.cl&#34;)
        self.cache = [None] * len(self)

    def __len__(self):
        return len(self.dataset)</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li>torch.utils.data.dataset.Dataset</li>
<li>typing.Generic</li>
</ul>
<h3>Methods</h3>
<dl>
<dt id="SpykeTorch.utils.CacheDataset.reset_cache"><code class="name flex">
<span>def <span class="ident">reset_cache</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Clears the cached data. It is useful when you want to change a pre-processing parameter during
the training process.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def reset_cache(self):
    r&#34;&#34;&#34;Clears the cached data. It is useful when you want to change a pre-processing parameter during
    the training process.
    &#34;&#34;&#34;
    if self.cache_address is not None:
        for add in self.cache:
            os.remove(add + &#34;.cd&#34;)
            os.remove(add + &#34;.cl&#34;)
    self.cache = [None] * len(self)</code></pre>
</details>
</dd>
</dl>
</dd>
</dl>
</section>
</article>
<nav id="sidebar">
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="SpykeTorch" href="index.html">SpykeTorch</a></code></li>
</ul>
</li>
<li><h3><a href="#header-functions">Functions</a></h3>
<ul class="">
<li><code><a title="SpykeTorch.utils.to_pair" href="#SpykeTorch.utils.to_pair">to_pair</a></code></li>
<li><code><a title="SpykeTorch.utils.generate_inhibition_kernel" href="#SpykeTorch.utils.generate_inhibition_kernel">generate_inhibition_kernel</a></code></li>
<li><code><a title="SpykeTorch.utils.tensor_to_text" href="#SpykeTorch.utils.tensor_to_text">tensor_to_text</a></code></li>
<li><code><a title="SpykeTorch.utils.text_to_tensor" href="#SpykeTorch.utils.text_to_tensor">text_to_tensor</a></code></li>
</ul>
</li>
<li><h3><a href="#header-classes">Classes</a></h3>
<ul>
<li>
<h4><code><a title="SpykeTorch.utils.LateralIntencityInhibition" href="#SpykeTorch.utils.LateralIntencityInhibition">LateralIntencityInhibition</a></code></h4>
<ul class="">
<li><code><a title="SpykeTorch.utils.LateralIntencityInhibition.intensity_lateral_inhibition" href="#SpykeTorch.utils.LateralIntencityInhibition.intensity_lateral_inhibition">intensity_lateral_inhibition</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="SpykeTorch.utils.FilterKernel" href="#SpykeTorch.utils.FilterKernel">FilterKernel</a></code></h4>
</li>
<li>
<h4><code><a title="SpykeTorch.utils.DoGKernel" href="#SpykeTorch.utils.DoGKernel">DoGKernel</a></code></h4>
</li>
<li>
<h4><code><a title="SpykeTorch.utils.GaborKernel" href="#SpykeTorch.utils.GaborKernel">GaborKernel</a></code></h4>
</li>
<li>
<h4><code><a title="SpykeTorch.utils.Filter" href="#SpykeTorch.utils.Filter">Filter</a></code></h4>
</li>
<li>
<h4><code><a title="SpykeTorch.utils.Intensity2Latency" href="#SpykeTorch.utils.Intensity2Latency">Intensity2Latency</a></code></h4>
<ul class="">
<li><code><a title="SpykeTorch.utils.Intensity2Latency.intensity_to_latency" href="#SpykeTorch.utils.Intensity2Latency.intensity_to_latency">intensity_to_latency</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="SpykeTorch.utils.CacheDataset" href="#SpykeTorch.utils.CacheDataset">CacheDataset</a></code></h4>
<ul class="">
<li><code><a title="SpykeTorch.utils.CacheDataset.reset_cache" href="#SpykeTorch.utils.CacheDataset.reset_cache">reset_cache</a></code></li>
</ul>
</li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc" title="pdoc: Python API documentation generator"><cite>pdoc</cite> 0.10.0</a>.</p>
</footer>
</body>
</html>